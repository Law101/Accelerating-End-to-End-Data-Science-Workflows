{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population data generator\n",
    "\n",
    "Population needs realistic data with the following parameters:\n",
    "\n",
    "- 66,435,550 people (sum of census data) or subset of that (e.g. England and Wales)\n",
    "- Each person has \n",
    "    - national ID number\n",
    "    - name\n",
    "    - age\n",
    "    - sex\n",
    "    - location (county, lat, long)\n",
    "    - field of employment\n",
    "    - health status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "UK_POP = 66435550"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### National Insurance numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_ni_numbers(n_uniques):\n",
    "    '''Returns n_uniques unique letter triplets for which the first two letters and the last letter, \n",
    "    when used as the prefix and suffix of a UK National Insurance number, are invalid.'''\n",
    "    \n",
    "    prefix_first_letters = [x for x in 'DFQUV'] # none of these is used in valid UK national insurance numbers\n",
    "    prefix_second_letters = [x for x in 'ABCDEFGHJKLMNPQRSTUVWXYZ'] # avoiding I and O\n",
    "    suffix_letters = [x for x in 'EFGHJKLMNPQRSTUVWXYZ'] # ABCD are the valid suffixes\n",
    "    \n",
    "    # generating twice as many as we expect to need, then filtering to uniques\n",
    "    first_list = np.random.choice(prefix_first_letters, n_uniques*2, replace=True)\n",
    "    second_list = np.random.choice(prefix_second_letters, n_uniques*2, replace=True)\n",
    "    suffix_list = np.random.choice(suffix_letters, n_uniques*2, replace=True)\n",
    "    \n",
    "    return(np.unique([x+y+z for x, y, z in zip(first_list, second_list, suffix_list)])[:n_uniques])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population quantity, age, sex, county locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_pop_dfs(m_file='county_pop_male_clean.csv', f_file='county_pop_female_clean.csv', county_file='county_locations_dec2016.csv', multiple=1):\n",
    "    # multiple changes the generated population to that fraction/multiple of the original\n",
    "\n",
    "    m = pd.read_csv(m_file)\n",
    "    f = pd.read_csv(f_file)\n",
    "    \n",
    "    # https://data.gov.uk/dataset/11302ddc-65bc-4a8f-96a9-af5c456e442c/counties-and-unitary-authorities-december-2016-full-clipped-boundaries-in-england-and-wales\n",
    "    county_locations = pd.read_csv(county_file)\n",
    "    keep_cols = list(county_locations['ctyua16nm'])\n",
    "    \n",
    "    # keep only those counties/unitary areas for which we have locational data (essentially England and Wales)\n",
    "    for col in m.columns:\n",
    "        if col not in keep_cols:\n",
    "            m.drop(columns=col, inplace=True)\n",
    "            f.drop(columns=col, inplace=True)\n",
    "    \n",
    "    if multiple == int(multiple):\n",
    "        return([m*multiple, f*multiple], county_locations)\n",
    "    else:\n",
    "        return([(m*multiple).apply(np.ceil), (f*multiple).apply(np.ceil)], county_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_name_dfs(m_file='2016_names_m_clean.csv', f_file='2016_names_f_clean.csv'):\n",
    "    m_names = pd.read_csv(m_file, thousands=',')\n",
    "    f_names = pd.read_csv(f_file, thousands=',')\n",
    "    \n",
    "    m_names['Name'] = m_names['Name'].str.strip()\n",
    "    f_names['Name'] = f_names['Name'].str.strip()\n",
    "    \n",
    "    m_names['freq'] = m_names['Count'] / m_names['Count'].sum()\n",
    "    f_names['freq'] = f_names['Count'] / f_names['Count'].sum()\n",
    "    \n",
    "    return([m_names, f_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location (lat/long)\n",
    "#### NEED THIS FOR NONEMPLOYMENT RISK FACTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def latlong2osgbgrid_cupy(lat, long, input_degrees=True):\n",
    "    '''\n",
    "    Converts latitude and longitude (ellipsoidal) coordinates into northing and easting (grid) coordinates, using a Transverse Mercator projection.\n",
    "    \n",
    "    Inputs:\n",
    "    lat: latitude coordinate (N)\n",
    "    long: longitude coordinate (E)\n",
    "    input_degrees: if True (default), interprets the coordinates as degrees; otherwise, interprets coordinates as radians\n",
    "    \n",
    "    Output:\n",
    "    (northing, easting)\n",
    "    '''\n",
    "    \n",
    "    if input_degrees:\n",
    "        lat = lat * cp.pi/180\n",
    "        long = long * cp.pi/180\n",
    "\n",
    "    a = 6377563.396\n",
    "    b = 6356256.909\n",
    "    e2 = (a**2 - b**2) / a**2\n",
    "\n",
    "    N0 = -100000 # northing of true origin\n",
    "    E0 = 400000 # easting of true origin\n",
    "    F0 = .9996012717 # scale factor on central meridian\n",
    "    phi0 = 49 * cp.pi / 180 # latitude of true origin\n",
    "    lambda0 = -2 * cp.pi / 180 # longitude of true origin and central meridian\n",
    "    \n",
    "    sinlat = cp.sin(lat)\n",
    "    coslat = cp.cos(lat)\n",
    "    tanlat = cp.tan(lat)\n",
    "    \n",
    "    latdiff = lat-phi0\n",
    "    longdiff = long-lambda0\n",
    "\n",
    "    n = (a-b) / (a+b)\n",
    "    nu = a * F0 * (1 - e2 * sinlat ** 2) ** -.5\n",
    "    rho = a * F0 * (1 - e2) * (1 - e2 * sinlat ** 2) ** -1.5\n",
    "    eta2 = nu / rho - 1\n",
    "    M = b * F0 * ((1 + n + 5/4 * (n**2 + n**3)) * latdiff - \n",
    "                  (3*(n+n**2) + 21/8 * n**3) * cp.sin(latdiff) * cp.cos(lat+phi0) +\n",
    "                  15/8 * (n**2 + n**3) * cp.sin(2*(latdiff)) * cp.cos(2*(lat+phi0)) - \n",
    "                  35/24 * n**3 * cp.sin(3*(latdiff)) * cp.cos(3*(lat+phi0)))\n",
    "    I = M + N0\n",
    "    II = nu/2 * sinlat * coslat\n",
    "    III = nu/24 * sinlat * coslat ** 3 * (5 - tanlat ** 2 + 9 * eta2)\n",
    "    IIIA = nu/720 * sinlat * coslat ** 5 * (61-58 * tanlat**2 + tanlat**4)\n",
    "    IV = nu * coslat\n",
    "    V = nu / 6 * coslat**3 * (nu/rho - np.tan(lat)**2)\n",
    "    VI = nu / 120 * coslat ** 5 * (5 - 18 * tanlat**2 + tanlat**4 + 14 * eta2 - 58 * tanlat**2 * eta2)\n",
    "\n",
    "    northing = I + II * longdiff**2 + III * longdiff**4 + IIIA * longdiff**6\n",
    "    easting = E0 + IV * longdiff + V * longdiff**3 + VI * longdiff**5\n",
    "\n",
    "    return(northing, easting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# <18: student (18 is the \"compulsory school age\")\n",
    "# 18-65: potentially employed\n",
    "# 65+: retired (65 is the state pension age)\n",
    "\n",
    "# from county pop data: 20376672 total m ages 18-65, 20530386 total f\n",
    "\n",
    "field_data = pd.read_csv('employment_field.csv')\n",
    "field_data = field_data.append({'Field': 'Not formally employed', \n",
    "                                'Code': 'Z', \n",
    "                                'Men': 20376672 - field_data.Men.sum(), \n",
    "                                'Women': 20530386 - field_data.Women.sum()}, \n",
    "                                ignore_index=True)\n",
    "field_probs = [field_data.Men / field_data.Men.sum()]\n",
    "field_probs.append(field_data.Women / field_data.Women.sum())\n",
    "\n",
    "# since we are only retaining field codes, for memory space, we put the decoding guide separately\n",
    "code_guide = field_data[['Code', 'Field']]\n",
    "code_guide = code_guide.append({'Code': 'U', 'Field': 'Student'}, ignore_index=True)\n",
    "code_guide = code_guide.append({'Code': 'V', 'Field': 'Retired'}, ignore_index=True)\n",
    "code_guide = code_guide.append({'Code': 'Y', 'Field': 'Pre-school child'}, ignore_index=True)\n",
    "code_guide = code_guide.sort_values('Code')\n",
    "code_guide.to_csv('code_guide.csv', index=False)\n",
    "\n",
    "def get_employment_field(age, sex, n):\n",
    "    if age < 5:\n",
    "        return(np.repeat('Y', n))\n",
    "    elif age < 18:\n",
    "        return(np.repeat('U', n))\n",
    "    elif age > 65:\n",
    "        return(np.repeat('V', n))\n",
    "    else:\n",
    "        return(np.random.choice(field_data.Code, size=n, replace=True, p=field_probs[sex]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infection risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_infection_risk(pop_df):\n",
    "\n",
    "    BASELINE_ODDS = 1/99   # infection chance before adjustments\n",
    "    CENTRAL_AGE = 31       # since we are adding one to each age, 30 is the inflection point of risk\n",
    "    HOTSPOT_E = 378953.474 # coordinates of \n",
    "    HOTSPOT_N = 385897.551 # St. Ambrose in Hale Barns\n",
    "    DECAY = -np.log(.5)    # half the risk\n",
    "    RADIUS = 100000        # every 100km\n",
    "    DECAY_RADIUS = RADIUS/DECAY\n",
    "    \n",
    "    # baseline\n",
    "    odds = BASELINE_ODDS\n",
    "    \n",
    "    # age adjustment: monotonically increasing with age, inflection point at CENTRAL_AGE - 1\n",
    "    odds = odds * (gdf.age + 1) / CENTRAL_AGE\n",
    "    \n",
    "    # sex adjustment: 2x for f\n",
    "    odds = odds * ((gdf.sex == 'f').astype('int') + 1)\n",
    "    \n",
    "    # location adjustment: centered on the hotspot\n",
    "    northing, easting = latlong2osgbgrid_cupy(cp.asarray(pop_df.lat.data.mem), cp.asarray(pop_df.long.data.mem))\n",
    "    odds = odds * cp.exp(( (easting - HOTSPOT_E)**2 + (northing - HOTSPOT_N)**2 )**.5  / DECAY_RADIUS)\n",
    "    \n",
    "    # employment adjustment: accommodations/food services or health/social work have increased risk\n",
    "    odds = odds * (cp.logical_or(gdf.employment_field == 'I', gdf.employment_field == 'Q') + 1)\n",
    "    \n",
    "    # convert to [0,1] probability for percentage interpretability (and random uniform number simplicity)\n",
    "    return(cp.asnumpy(odds / (1+odds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def stats_to_individuals(pop_dfs, locations, name_dfs, verbose=False):\n",
    "    df_list = []\n",
    "    \n",
    "    # originally, prefixes were geographical; their current method of generation is nonpublic\n",
    "    num_counties = pop_dfs[0].shape[1]\n",
    "    county_prefixes_suffixes = generate_ni_numbers(num_counties)\n",
    "\n",
    "    # generating everything that depends on age, sex, or county\n",
    "    # it doesn't matter whether 0 or 1 is m or f, but for the exercises we assume f=1\n",
    "    for sex, d in enumerate(pop_dfs):\n",
    "        name_vals = name_dfs[sex]['Name']\n",
    "        name_freq = name_dfs[sex]['freq']\n",
    "        \n",
    "        # this ordering assumes there are more counties than ages to be efficient\n",
    "        for county in range(d.shape[1]):\n",
    "            # get the county National Insurance prefix/suffix\n",
    "            county_prefix = county_prefixes_suffixes[county][:2]\n",
    "            county_suffix = county_prefixes_suffixes[county][2]\n",
    "            \n",
    "            # get the county centroids and sizes\n",
    "            lat, long, area = locations.loc[locations['ctyua16nm'] == d.columns[county], ['lat', 'long', 'st_areashape']].iloc[0]\n",
    "            # 99% of people within 3 standard deviations of the centroid\n",
    "            std_m = np.sqrt(area) / 3\n",
    "            \n",
    "            for age in range(d.shape[0]):\n",
    "                n = int(d.iloc[age, county])\n",
    "                \n",
    "                # can put all kinds of features conditional on age/sex/location here\n",
    "\n",
    "                # location\n",
    "                if verbose:\n",
    "                    loc_start_time = time.time()\n",
    "                # each 0.1 degrees of lat is ~11.1km\n",
    "                lat_array = np.random.normal(lat, std_m/111000, n)\n",
    "                # at 51N latitude, each 0.1 degrees of long is ~7km\n",
    "                # at 55N latitude, each 0.1 degrees of long is ~6.4km\n",
    "                long_array = np.random.normal(long, std_m/67000, n)\n",
    "                if verbose:\n",
    "                    print(f'location time: {time.time() - loc_start_time} sec')\n",
    "                \n",
    "                if verbose:\n",
    "                    name_start_time = time.time()\n",
    "                # names pulled from https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/livebirths/datasets/babynamesenglandandwalesbabynamesstatisticsgirls\n",
    "                # could augment conditional probaiblities by year, for years with available data\n",
    "                names = np.random.choice(name_vals, n, replace=True, p=name_freq)\n",
    "                if verbose:\n",
    "                    print(f'name time: {time.time() - name_start_time} sec')\n",
    "                \n",
    "                if verbose:\n",
    "                    nid_start_time = time.time()\n",
    "                # national ID (National Insurance Number)\n",
    "                #nid_numbers = np.random.choice(1000000, n, replace=False)\n",
    "                #nids = [f'{county_prefix}-{x}-{county_suffix}' for x in nid_numbers]\n",
    "                if verbose:\n",
    "                    print(f'nid time: {time.time() - nid_start_time} sec')\n",
    "                \n",
    "                if verbose:\n",
    "                    emp_start_time = time.time()\n",
    "                # employment\n",
    "                field_list = get_employment_field(age, sex, n)\n",
    "                if verbose:\n",
    "                    print(f'employment time: {time.time() - emp_start_time} sec')\n",
    "                \n",
    "                if verbose:\n",
    "                    append_start_time = time.time()\n",
    "                df_list.append(pd.DataFrame({#'ni_number': nids,\n",
    "                                             'ni_number': np.repeat(0, n),\n",
    "                                             'name': names,\n",
    "                                             'age': np.repeat(int(age), n), \n",
    "                                             'sex': np.repeat(['m', 'f'][sex], n), \n",
    "                                             'county': np.repeat(d.columns[county].upper(), n),\n",
    "                                             'lat': lat_array,\n",
    "                                             'long': long_array,\n",
    "                                             'employment': field_list\n",
    "                                             }))\n",
    "                if verbose:\n",
    "                    print(f'append time: {time.time() - append_start_time} sec')\n",
    "                \n",
    "            if county % 25 == 0:\n",
    "                print(f'county {county} complete')\n",
    "        print(f'sex {sex} complete')\n",
    "\n",
    "    pop_df = pd.concat(df_list, ignore_index=True, copy=False)\n",
    "    \n",
    "    # generating features that are nationally uniform and thus we can do in a single shot\n",
    "    if verbose:\n",
    "        inf_start_time = time.time()\n",
    "    #pop_df['infection_risk'] = get_infection_risk(pop_df)\n",
    "    #pop_df['infection_rand'] = np.random.uniform(size=pop_df.shape[0])\n",
    "    if verbose:\n",
    "        print(f'infection time: {time.time() - inf_start_time} sec')\n",
    "    \n",
    "    return(pop_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piecewise creation\n",
    "\n",
    "#### Creating a baseline population\n",
    "Only needs to be run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pop_dfs, county_locations = get_pop_dfs(multiple=1)\n",
    "print(sum([x.sum().sum() for x in pop_dfs]), 'simulated people')\n",
    "%time name_dfs = get_name_dfs()\n",
    "\n",
    "# stats_to_individuals currently has ni_number and infection_risk disabled\n",
    "# infection_risk is applied later, ni_number will need to be generated using the function if desired (takes a while)\n",
    "%time new_pop = stats_to_individuals(pop_dfs, county_locations, name_dfs, verbose=False)\n",
    "%time new_pop.to_csv('new_pop.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create random health status for comparison with infection risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_rand = cudf.Series(np.random.uniform(size=new_pop.shape[0]))\n",
    "rand_df = cudf.DataFrame()\n",
    "rand_df['rand'] = inf_rand\n",
    "%time rand_df.to_csv('rand_unif.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establishing infection risk from nonemployment factors\n",
    "Tune this to get the distribution and quantity desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 s, sys: 1.38 s, total: 5.38 s\n",
      "Wall time: 5.53 s\n",
      "   age sex        lat      long\n",
      "0    0   m  54.522510 -1.571896\n",
      "1    0   m  54.554030 -1.524968\n",
      "2    0   m  54.552486 -1.435203\n",
      "3    0   m  54.537189 -1.566215\n",
      "4    0   m  54.528212 -1.588462\n",
      "CPU times: user 1.73 s, sys: 10.8 ms, total: 1.74 s\n",
      "Wall time: 1.75 s\n",
      "CPU times: user 548 ms, sys: 303 ms, total: 850 ms\n",
      "Wall time: 946 ms\n",
      "CPU times: user 4.16 s, sys: 22.5 ms, total: 4.18 s\n",
      "Wall time: 4.21 s\n",
      "CPU times: user 275 ms, sys: 6.54 ms, total: 282 ms\n",
      "Wall time: 281 ms\n",
      "CPU times: user 174 ms, sys: 7.67 ms, total: 182 ms\n",
      "Wall time: 183 ms\n"
     ]
    }
   ],
   "source": [
    "%time gdf = cudf.read_csv('new_pop.csv', usecols=['age', 'sex', 'lat', 'long'])\n",
    "print(gdf.head())\n",
    "\n",
    "# manual version of the combined function, to do more detailed inspection\n",
    "\n",
    "BASELINE_ODDS = 1/99   # infection chance before adjustments\n",
    "\n",
    "MAX_AGE_ODDS = 2       # age risk odds multiple varies from ~0 to ~2\n",
    "YEARS_TO_MAX = 30      # number of years between central age (risk ratio = 1) and the point of MAX_AGE_ODDS\n",
    "CENTRAL_AGE = 31       # since we are adding one to each age, 30 is the inflection point of risk\n",
    "\n",
    "HOTSPOT_E = 378953.474 # coordinates of \n",
    "HOTSPOT_N = 385897.551 # St. Ambrose in Hale Barns\n",
    "DECAY = np.log(.5)    # half the risk\n",
    "RADIUS = 100000        # every 100km\n",
    "DECAY_RADIUS = RADIUS/DECAY\n",
    "\n",
    "# logistic function for age risk\n",
    "%time age_risk = MAX_AGE_ODDS / (1 + cp.exp(-5 / YEARS_TO_MAX * (cp.asarray(gdf.age.data.mem, dtype='float32') - CENTRAL_AGE)))\n",
    "\n",
    "# per https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3035551/\n",
    "%time sex_risk = ((gdf.sex == 'f').astype('float32') + 0.5)\n",
    "\n",
    "# exponential decay with distance\n",
    "%time northing, easting = latlong2osgbgrid_cupy(cp.asarray(gdf.lat.data.mem, dtype='float32'), cp.asarray(gdf.long.data.mem, dtype='float32'))\n",
    "%time dist_risk = cp.exp(( (easting - HOTSPOT_E)**2 + (northing - HOTSPOT_N)**2 )**.5  / DECAY_RADIUS)\n",
    "del(northing)\n",
    "del(easting)\n",
    "\n",
    "%time odds = cudf.Series(age_risk) * sex_risk * cudf.Series(dist_risk) * BASELINE_ODDS #* emp_risk\n",
    "del(age_risk)\n",
    "del(sex_risk)\n",
    "del(dist_risk)\n",
    "\n",
    "del(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 2.69 s, total: 4.11 s\n",
      "Wall time: 6.08 s\n"
     ]
    }
   ],
   "source": [
    "out_df = cudf.DataFrame()\n",
    "out_df['odds'] = odds\n",
    "%time out_df.to_csv('nonemp_risk.csv', index=False)\n",
    "del(out_df)\n",
    "del(odds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining in employment risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.32 s, sys: 942 ms, total: 4.26 s\n",
      "Wall time: 4.28 s\n",
      "CPU times: user 366 ms, sys: 3.09 ms, total: 369 ms\n",
      "Wall time: 378 ms\n",
      "CPU times: user 1.15 s, sys: 678 ms, total: 1.83 s\n",
      "Wall time: 1.84 s\n",
      "CPU times: user 178 ms, sys: 0 ns, total: 178 ms\n",
      "Wall time: 179 ms\n",
      "count    5.847989e+07\n",
      "mean     5.027000e-03\n",
      "std      6.645000e-03\n",
      "min      2.000000e-06\n",
      "25%      7.110000e-04\n",
      "50%      2.627000e-03\n",
      "75%      6.362000e-03\n",
      "max      5.685100e-02\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "%time emp = cudf.read_csv('new_pop.csv', usecols=['employment'])\n",
    "\n",
    "# employment adjustment: accommodations/food services or health/social work have increased risk\n",
    "acc_food = (emp.employment == 'I')\n",
    "health_social = (emp.employment == 'Q')\n",
    "%time emp_risk = (acc_food | health_social).astype('int32') + 1\n",
    "\n",
    "%time nonemp_risk = cudf.read_csv('nonemp_risk.csv')\n",
    "\n",
    "%time total_risk = emp_risk * nonemp_risk.odds\n",
    "total_risk = total_risk / (total_risk + 1)\n",
    "\n",
    "print(total_risk.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.52 s, sys: 2.52 s, total: 4.04 s\n",
      "Wall time: 5.68 s\n"
     ]
    }
   ],
   "source": [
    "out_df = cudf.DataFrame()\n",
    "out_df['total_risk'] = total_risk\n",
    "%time out_df.to_csv('total_risk.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating infection status\n",
    "Once for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    57602226\n",
      "True       877668\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "rand_df = cudf.read_csv('rand_unif.csv')\n",
    "inf_rand = rand_df['rand']\n",
    "del(rand_df)\n",
    "\n",
    "risk_df = cudf.read_csv('total_risk.csv')\n",
    "total_risk = risk_df['total_risk']\n",
    "del(risk_df)\n",
    "\n",
    "infected = total_risk.gt(inf_rand + 0) # change this value\n",
    "print(infected.value_counts())\n",
    "\n",
    "# Day 0 (+0.03 to rand):    4960\n",
    "# Day 1 (+0.02 to rand):   18148\n",
    "# Day 2 (+0.01 to rand):   70880\n",
    "# Day 3 (neutral):        293707\n",
    "# Day 4 (-0.01 to rand):  877668\n",
    "\n",
    "inf_df = cudf.DataFrame()\n",
    "inf_df['infected'] = infected\n",
    "inf_df.to_csv('infected_dayX.csv', index=False) # change the file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.94 s, sys: 1.45 s, total: 5.4 s\n",
      "Wall time: 5.53 s\n",
      "False    58461746\n",
      "True        18148\n",
      "Name: infected, dtype: int32\n",
      "CPU times: user 9.79 s, sys: 13.8 s, total: 23.6 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "# age, sex, employment, lat, long, infection status... county may be too many columns\n",
    "\n",
    "%time pop_data = cudf.read_csv('new_pop.csv', usecols=['age', 'sex', 'employment', 'lat', 'long'])\n",
    "infection = cudf.read_csv('infected_day1.csv')\n",
    "print(infection['infected'].value_counts())\n",
    "\n",
    "day1 = cudf.multi.concat([pop_data, infection], axis=1)\n",
    "%time day1.to_csv('day1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 s, sys: 886 ms, total: 4.29 s\n",
      "Wall time: 4.28 s\n",
      "False    58409014\n",
      "True        70880\n",
      "Name: infected, dtype: int32\n",
      "CPU times: user 5.1 s, sys: 8.51 s, total: 13.6 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "# lat, long, infection status\n",
    "\n",
    "%time pop_data = cudf.read_csv('new_pop.csv', usecols=['lat', 'long'])\n",
    "infection = cudf.read_csv('infected_day2.csv')\n",
    "print(infection['infected'].value_counts())\n",
    "\n",
    "day2 = cudf.multi.concat([pop_data, infection], axis=1)\n",
    "%time day2.to_csv('day2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.55 s, sys: 950 ms, total: 4.5 s\n",
      "Wall time: 4.45 s\n",
      "False    58186187\n",
      "True       293707\n",
      "Name: infected, dtype: int32\n",
      "CPU times: user 4.68 s, sys: 6.81 s, total: 11.5 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "# lat, long, infection status\n",
    "\n",
    "%time pop_data = cudf.read_csv('new_pop.csv', usecols=['lat', 'long'])\n",
    "infection = cudf.read_csv('infected_day3.csv')\n",
    "print(infection['infected'].value_counts())\n",
    "\n",
    "day3 = cudf.multi.concat([pop_data, infection], axis=1)\n",
    "%time day3.to_csv('day3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original sequence to clean the raw Nomis census data\n",
    "\n",
    "Based on tables with county columns and age rows, separated by sex"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "female = cudf.read_csv('county_pop_female.csv')\n",
    "male = cudf.read_csv('county_pop_male.csv')\n",
    "\n",
    "print(female.shape, male.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(female.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Age aligns exactly with the normal index series, so we can drop it\n",
    "female.drop_column(list(female.columns)[0])\n",
    "male.drop_column(list(male.columns)[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "total = female + male\n",
    "\n",
    "print(total.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(total.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# we want the name of the county, not its prefix\n",
    "total.columns = cudf.Series(total.columns).str.split(':')[1]\n",
    "print(total.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "female.columns = cudf.Series(female.columns).str.split(':')[1]\n",
    "cudf.io.csv.to_csv(female, '/cmilroy/rapids_dli/county_pop_female_clean.csv', index=False)\n",
    "male.columns = cudf.Series(male.columns).str.split(':')[1]\n",
    "cudf.io.csv.to_csv(male, '/cmilroy/rapids_dli/county_pop_male_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cudf.io.csv.to_csv(total, '/cmilroy/rapids_dli/county_pop_total.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
